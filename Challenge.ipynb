{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between Sample 1 and Sample 2  35.22217634423552\n",
      "Similarity between Sample 1 and Sample 3  74.65084498804694\n"
     ]
    }
   ],
   "source": [
    "import math \n",
    "import string \n",
    "import sys\n",
    "\n",
    "def get_words_from_line_list(text):  \n",
    "    \n",
    "    # Pre processing the given samples.\n",
    "    \n",
    "    pre_process = str.maketrans(string.punctuation+string.ascii_uppercase,\" \"*len(string.punctuation)+string.ascii_lowercase)\n",
    "    \n",
    "    text = text.translate(pre_process) \n",
    "    \n",
    "    # Splitting the text into individual words\n",
    "    word_list = text.split() \n",
    "\n",
    "    b= []\n",
    "\n",
    "    # Ignoring the words of length 2 as these do not make any contribution in preedicting the outcome.\n",
    "    for i in word_list:\n",
    "        if len(i) > 2:\n",
    "            b.append(i)\n",
    "            \n",
    "    # checking if the words in our list are stopwords or not. If stopwords, we ignore them\n",
    "    stopWords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now']\n",
    "    c = []\n",
    "    for k in b:\n",
    "        if k not in stopWords:\n",
    "            c.append(k)\n",
    "      \n",
    "    # Using a Dictionary to find out the words and number of the times occuring\n",
    "    D = {}   \n",
    "    for j in c:    \n",
    "        if j in D: \n",
    "            D[j] = D[j] + 1\n",
    "              \n",
    "        else: \n",
    "            D[j] = 1\n",
    "    return D\n",
    "\n",
    "f = ''' The easiest way to earn points with Fetch Rewards is to just shop for the items you already buy. If you have any eligible brands on your receipt, you will get points based on the total cost of the products. You do not need to cut out any coupons or scan individual UPCs. Just scan your receipt after you check out and we will find the savings for you. '''\n",
    "f1 = ''' The easiest way to earn points with Fetch Rewards is to just shop for the products you already love. If you have any participating brands on your receipt, you'll get points based on the cost of the products. You don't need to clip any coupons or scan individual barcodes. Just scan each grocery receipt after you shop and we'll find the savings for you. '''\n",
    "f2 = ''' We are always looking for opportunities for you to earn more points, which is why we also give you a selection of Special Offers. These Special Offers are opportunities to earn bonus points on top of the regular points you earn every time you purchase a participating brand. No need to pre-select these offers, we'll give you the points whether or not you knew about the offer. We just think it is easier that way. '''\n",
    "\n",
    "s = get_words_from_line_list(f)\n",
    "s1 = get_words_from_line_list(f1)\n",
    "s2 = get_words_from_line_list(f2)\n",
    "\n",
    "# Here we treat samples as vectors and calculate angle between two given document samples using cos(d) = s1.s2/(|s|*|s1|)\n",
    "\n",
    "def Dotproduct(s,s1):\n",
    "      \n",
    "    sum = 0.0 \n",
    "    for i in s:         \n",
    "        if i in s1 : \n",
    "            sum += (s[i] * s1[i]) \n",
    "    return sum\n",
    "                \n",
    "n = Dotproduct(s,s1)\n",
    "n1 = Dotproduct(s,s2)\n",
    "d = math.sqrt(Dotproduct(s, s)*Dotproduct(s1, s1)) \n",
    "d1 = math.sqrt(Dotproduct(s, s)*Dotproduct(s2, s2)) \n",
    "distance = math.acos(n / d)\n",
    "distance1 = math.acos(n1 / d1)\n",
    "\n",
    "print(\"Similarity between Sample 1 and Sample 2 \",math.degrees(distance)) \n",
    "print(\"Similarity between Sample 1 and Sample 3 \",math.degrees(distance1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d-range is between (0 and 90). When d is 0 degrees means the two documents are exactly identical and when d is 90 degrees means the two documents are different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here as \"Similarity between Sample 1 and Sample 2 is 35.22217634423552\", that means they are near to identical\n",
    " and as \"Similarity between Sample 1 and Sample 3 is 74.65084498804694\", that means they are almost different. \n",
    "\"\"\"   Samples 1 and 2 are more similar than samples 1 and 3.  \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
